# -*- coding: utf-8 -*-
"""view_entities.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jqr1PqdqiHYOPpMNyFto_r1UxvQVhQuL
"""

'''
# mount drive
from google.colab import drive
drive.mount('/content/drive')
'''

'''
!pip install -U scispacy==0.3.0
!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.3.0/en_core_sci_sm-0.3.0.tar.gz
#!pip3 install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.0/en_core_web_sm-2.2.0.tar.gz
#!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_core_sci_sm-0.5.1.tar.gz
'''

import os
from glob import glob
import csv
import json
import hashlib
import requests
from tqdm import tqdm
import time
import spacy
import scispacy
from scispacy.linking import EntityLinker
from spacy import displacy

'''
def clean_text(text):
  """Remove section titles and figure descriptions from text"""
  clean = "\n".join([row for row in text.split("\n") if (len(row.split(" "))) > 3 and not (row.startswith("(a)")) and not row.startswith("Figure")])
  return clean
'''
############################
def clean_pars(text):
   clean = "\n".join([row for row in text.split("\n") if (len(row.split(" "))) > 3 and not (row.startswith("(a)")) and not row.startswith("Figure")])
   return clean

def clean_text(text):
  """Remove section titles and figure descriptions from text"""
  pars = [row for row in text.split("\n\n")]
  cpars = list(map(clean_pars, pars))
  return cpars
############################

def load_entity_linker(threshold=0.90):
  nlp = spacy.load("en_core_sci_sm")
  linker = EntityLinker(
    resolve_abbreviations=True,
    name="umls",
    threshold=threshold)
  nlp.add_pipe(linker)
  return nlp, linker

def entity_linking_to_umls(txt, nlp, linker):
  doc = nlp(txt)
  entities = doc.ents
  all_entities_results = []
  for mm in range(len(entities)):
    entity_text = entities[mm].text
    entity_start = entities[mm].start_char
    entity_end = entities[mm].end_char
    all_linked_entities = entities[mm]._.kb_ents
    all_linked_names = []
    for ii in range(len(all_linked_entities)):
      curr_scispacy_entity = linker.kb.cui_to_entity[all_linked_entities[ii][0]]
      curr_canonical_name = curr_scispacy_entity.canonical_name
      all_linked_names.append(curr_canonical_name)

    if len(all_linked_names) == 0:
      my_label = "None"
    else:
      my_label = all_linked_names[0]

    curr_entities_result = {"start": entity_start, "end": entity_end, "label": my_label}
    all_entities_results.append(curr_entities_result)
  return {"text": txt, "ents": all_entities_results, "title": None}

def combine_par(dict_a, dict_b):
  dict_a_txt_len = len(dict_a['text'])
  combined_txt = dict_a['text'] + dict_b['text']
  combined_ents = dict_a['ents']
  for cur_ent in dict_b['ents']:
    cur_ent['start'] += dict_a_txt_len
    cur_ent['end'] += dict_a_txt_len
    combined_ents.append(cur_ent)
  return {"text": combined_txt, "ents": combined_ents, "title": None}

nlp, linker = load_entity_linker()

text_file_dir = "/content/drive/MyDrive/nlp_proj/article_txt_files"
files = sorted(glob(os.path.join(text_file_dir, "*")))
text = []
file_count = 0
# processing each file independently
for file in files[:1]:
  file_count += 1
  fd = open(file, "r", encoding='utf8')
  text.append(fd.read())
  article_txt = "\n".join(text)
  ctext_list = clean_text(article_txt)
  par_count = 0
  dict_to_be_render = entity_linking_to_umls(ctext_list[0], nlp, linker)
  for i in range(1, len(ctext_list)):
    par_count += 1
    dict_to_be_render = combine_par(dict_to_be_render, entity_linking_to_umls(ctext_list[i], nlp, linker))
    '''
    # to see whether combining paragraphs are successful
    if par_count == 3:
      print(dict_to_be_render)
      print("")
      break
    '''
  html = displacy.render(dict_to_be_render, manual=True, style="ent")
  file = open("visulization" + str(file_count) + str(par_count) + ".html", "w")
  file.write(html)
  file.close()
    
'''
  for ctext in ctext_list:
    par_count += 1
    dict_to_be_render = entity_linking_to_umls(ctext, nlp, linker)
    print(dict_to_be_render)
    print(len(dict_to_be_render['text']))
    if par_count == 2:
      break
    #html = displacy.render(dict_to_be_render, manual=True, style="ent")
    #file = open("visulization" + str(file_count) + str(par_count) + ".html", "w")
    #file.write(html)
    #file.close()
'''